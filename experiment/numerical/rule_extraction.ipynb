{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold, datasets\n",
    "import pickle\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.covariance import MinCovDet\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "sys.path.append('..')\n",
    "from lib.data_encoding import german_credit_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn -0.9258200997725516 -0.07838233761296741 (10423,)\n",
      "lof 0.9737859486100009 4.211928200115308 (10423,)\n",
      "iforest 0.29394066764582155 0.3476671119984273 (10423,)\n",
      "ocsvm -1421.6101449685095 -1.0811459656091529 (10423,)\n",
      "dbscan 0 1 (10423,)\n",
      "before fit (10423, 5) (10423,)\n",
      "after fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class DetectorEnsemble:\n",
    "    def __init__(self):\n",
    "        self.detectors = []\n",
    "        '''\n",
    "        self.detectors.append(('iforest1', IsolationForest(random_state = 0, max_samples = 128, n_estimators = 100)))\n",
    "        self.detectors.append(('iforest2', IsolationForest(random_state = 0, max_samples = 128, n_estimators = 200)))\n",
    "        self.detectors.append(('iforest3', IsolationForest(random_state = 0, max_samples = 256, n_estimators = 100)))\n",
    "        self.detectors.append(('iforest4', IsolationForest(random_state = 0, max_samples = 256, n_estimators = 200)))\n",
    "        self.detectors.append(('iforest5', IsolationForest(random_state = 0, max_samples = 512, n_estimators = 100)))\n",
    "        self.detectors.append(('iforest6', IsolationForest(random_state = 0, max_samples = 512, n_estimators = 200)))\n",
    "        '''\n",
    "        self.detectors.append(('knn', NearestNeighbors(algorithm='ball_tree')))\n",
    "        self.detectors.append(('lof', LocalOutlierFactor(metric=\"precomputed\")))\n",
    "        #self.detectors.append(('robustcov', MinCovDet()))\n",
    "        self.detectors.append(('iforest', IsolationForest()))\n",
    "        self.detectors.append(('ocsvm', OneClassSVM()))\n",
    "        self.detectors.append(('dbscan',  DBSCAN()))\n",
    "    \n",
    "    def fit_detector(self, X, y):\n",
    "        self.clf = LinearRegression(fit_intercept=True, normalize=False, copy_X=True).fit(X, y)\n",
    "\n",
    "    def fit(self, mat):\n",
    "        dist = pairwise_distances(X = mat, metric='euclidean')\n",
    "        self.scores = []\n",
    "        for (name, detector) in self.detectors:\n",
    "            if name[:3] == 'lof':\n",
    "                detector.fit_predict(dist)\n",
    "                self.scores.append(-detector.negative_outlier_factor_)\n",
    "            elif name == 'robustcov':\n",
    "                detector.fit(mat)\n",
    "                self.scores.append(detector.mahalanobis(mat))\n",
    "            elif name == 'knn':\n",
    "                detector.fit(mat)\n",
    "                self.scores.append(-detector.kneighbors(mat)[0][:, -1])\n",
    "            elif name == 'dbscan':\n",
    "                detector.fit(mat)\n",
    "                score = np.array([1 if x == -1 else 0 for x in detector.labels_])\n",
    "                self.scores.append(score)\n",
    "            else:\n",
    "                detector.fit_predict(mat)\n",
    "                self.scores.append(-detector.score_samples(mat))\n",
    "            print(name, min(self.scores[-1]), max(self.scores[-1]), self.scores[-1].shape)\n",
    "        tmp = []\n",
    "        for score in self.scores:\n",
    "            min_s = np.min(score)\n",
    "            max_s = np.max(score)\n",
    "            range_s = max(1, max_s - min_s)\n",
    "            score = (score - min_s) / range_s\n",
    "            tmp.append(score)\n",
    "        self.n = mat.shape[0]\n",
    "        self.scores = np.array(tmp)\n",
    "        self.ground_truth = {}\n",
    "        self.adjust_sample_weight = self.n // 100\n",
    "        self.weights = np.ones(len(self.detectors))\n",
    "        weights = self.weights / np.sum(self.weights)\n",
    "\n",
    "        self.scores = self.scores.transpose()\n",
    "        y = (self.scores * weights).sum(axis = 1)\n",
    "        print('before fit', self.scores.shape, y.shape)\n",
    "        self.fit_detector(self.scores, y)\n",
    "        print('after fit')\n",
    "    \n",
    "    def weighted_score(self):\n",
    "        y = self.clf.predict(self.scores)\n",
    "        for i in self.ground_truth:\n",
    "            y[i] = self.ground_truth[i]\n",
    "        return y\n",
    "\n",
    "    def adjust_weight(self, idx, score):\n",
    "        self.ground_truth[idx] = score\n",
    "        sample_weight = np.ones(self.n)\n",
    "        for i in self.ground_truth:\n",
    "            sample_weight[i] = self.adjust_sample_weight\n",
    "        y = self.weighted_score()\n",
    "        self.fit_detector(self.scores, y)\n",
    "\n",
    "\n",
    "model = pickle.load(open('../../output/dump/german0315v2.pkl', 'rb'))\n",
    "paths = model['paths']\n",
    "features = model['features']\n",
    "mat = np.array([p['sample'] for p in paths]).astype('float')\n",
    "for i in range(mat.shape[0]):\n",
    "    mat[i] = mat[i] > 0\n",
    "    mat[i] /= mat[i].sum() #np.sqrt(mat[i].sum())\n",
    "all_dist = pairwise_distances(X = mat, metric='euclidean')\n",
    "\n",
    "\n",
    "ensemble = DetectorEnsemble()\n",
    "ensemble.fit(mat)\n",
    "selected_path_idxes = ensemble.weighted_score().argsort()[::-1]\n",
    "\n",
    "output_labels = ['reject', 'accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4695, 4941, 8563, 2622, 7859, 9887, 6820, 9186, 3602, 1717, 476, 4272, 3016, 3733, 10158, 10067, 8246, 3206, 5387, 9237, 8978, 885, 4201, 9999, 1013, 1421, 10064, 10367, 8197, 7640, 7571, 2998, 9797, 8013, 10272, 7357, 333, 6030, 9776, 10374, 8802, 3325, 2844, 6374, 4891, 63, 8683, 3195, 6024, 127]\n"
     ]
    }
   ],
   "source": [
    "print(selected_path_idxes.tolist()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_count = 50\n",
    "expected_one_class_count = 40\n",
    "output_labels = ['reject', 'accept']\n",
    "\n",
    "iforest_idxes = [4695, 4941, 8563, 2622, 7859, 9887, 6820, 9186, 3602, 1717, 476, 4272, 3016, 3733, 10158, 10067, 8246, 3206, 5387, 9237, 8978, 885, 4201, 9999, 1013, 1421, 10064, 10367, 8197, 7640, 7571, 2998, 9797, 8013, 10272, 7357, 333, 6030, 9776, 10374, 8802, 3325, 2844, 6374, 4891, 63, 8683, 3195, 6024, 127]\n",
    "diff_idxes = [3719, 1572, 1224, 4632, 7869, 1788, 8489, 6267, 7082, 4721, 1032, 703, 6656, 10175, 5548, 10290, 6786, 1765, 7510, 2258, 3978, 71, 10180, 4910, 683, 1862, 1200, 5783, 4978, 4290, 2000, 185, 3032, 2324, 3306, 800, 802, 4821, 10297, 2247, 10029, 917, 3192, 2756, 847, 4706, 9480, 3682, 7524, 7616]\n",
    "selected_path_idxes = diff_idxes + iforest_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_encoding = {\n",
    "    'credit_risk' : ['No', 'Yes'], \n",
    "    'credit_history' : [\n",
    "        \"delay in paying off in the past\",\n",
    "        \"critical account/other credits elsewhere\",\n",
    "        \"no credits taken/all credits paid back duly\",\n",
    "        \"existing credits paid back duly till now\",\n",
    "        \"all credits at this bank paid back duly\",\n",
    "    ],\n",
    "    'purpose' : [\n",
    "        \"others\",\n",
    "        \"car (new)\",\n",
    "        \"car (used)\",\n",
    "        \"furniture/equipment\",\n",
    "        \"radio/television\",\n",
    "        \"domestic appliances\",\n",
    "        \"repairs\",\n",
    "        \"education\",\n",
    "        \"vacation\",\n",
    "        \"retraining\",\n",
    "        \"business\"\n",
    "    ],\n",
    "    'installment_rate': [\"< 20\", \"20 <= ... < 25\",  \"25 <= ... < 35\", \">= 35\"],\n",
    "    'present_residence': [\n",
    "        \"< 1 yr\", \n",
    "        \"1 <= ... < 4 yrs\",\n",
    "        \"4 <= ... < 7 yrs\", \n",
    "        \">= 7 yrs\"\n",
    "    ],\n",
    "    'number_credits': [\"1\", \"2~3\", \"4~5\", \">= 6\"],\n",
    "    'people_liable': [\"0 to 2\", \"3 or more\"],\n",
    "    'savings': [\n",
    "        \"unknown/no savings account\",\n",
    "        \"... <  100 DM\", \n",
    "        \"100 <= ... <  500 DM\",\n",
    "        \"500 <= ... < 1000 DM\", \n",
    "        \"... >= 1000 DM\",\n",
    "    ],\n",
    "    'employment_duration': [\n",
    "        \"unemployed\", \n",
    "        \"< 1 yr\", \n",
    "        \"1 <= ... < 4 yrs\",\n",
    "        \"4 <= ... < 7 yrs\", \n",
    "        \">= 7 yrs\"\n",
    "    ],\n",
    "    'personal_status_sex': [\n",
    "        \"not married male\",\n",
    "        \"married male\",\n",
    "    ],\n",
    "    'other_debtors': [\n",
    "        'none',\n",
    "        'co-applicant',\n",
    "        'guarantor'\n",
    "    ],\n",
    "    'property': [\n",
    "        \"real estate\",\n",
    "        \"building soc. savings agr./life insurance\", \n",
    "        \"car or other\",\n",
    "        \"unknown / no property\",\n",
    "    ],\n",
    "    'other_installment_plans': ['bank', 'stores', 'none'],\n",
    "    'housing': [\"rent\", \"own\", \"for free\"],\n",
    "    'job': [\n",
    "        'unemployed/ unskilled - non-resident',\n",
    "        'unskilled - resident',\n",
    "        'skilled employee / official',\n",
    "        'management/ self-employed/ highly qualified employee/ officer'\n",
    "    ],\n",
    "    'status': [\n",
    "        \"no checking account\",\n",
    "        \"... < 0 DM\",\n",
    "        \"0<= ... < 200 DM\",\n",
    "        \"... >= 200 DM / salary for at least 1 year\",\n",
    "    ],\n",
    "    'telephone': ['No', 'Yes'],\n",
    "    'foreign_worker': ['No', 'Yes'],\n",
    "}\n",
    "rule_type = [\n",
    "    1,1,1,1,1, 0,0,0,0,1, \n",
    "    0,0,0,1,1, 0,0,0,1,0,\n",
    "    0,1,0,1,1, 0,0,0,0,1,\n",
    "    1,1,0,0,0, 0,0,1,0,1,\n",
    "    0,0,1,0,1, 0,0,1,0,1\n",
    "] + [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "mat2 = np.array([p['sample'] for p in paths]).astype('float')\n",
    "for i in range(mat2.shape[0]):\n",
    "    mat2[i] = mat2[i] > 0\n",
    "    mat2[i] /= np.sqrt(mat2[i].sum())\n",
    "all_dist = pairwise_distances(X = mat2, metric='cosine')\n",
    "scores = ensemble.weighted_score()\n",
    "score_with_idx = [(-x, i) for i, x in enumerate(scores)]\n",
    "score_with_idx.sort()\n",
    "rank = {}\n",
    "for it, x in enumerate(score_with_idx):\n",
    "    rank[x[1]] = it\n",
    "\n",
    "anomaly_idxes = [x for i, x in enumerate(selected_path_idxes) if rule_type[i] > 0]\n",
    "sample_counts = [(np.sum(paths[i]['sample']), i) for i in anomaly_idxes]\n",
    "sample_counts.sort()\n",
    "sample_counts = sample_counts[::-1]\n",
    "anomaly_idxes = [x[1] for x in sample_counts]\n",
    "sample_counts = [x[0] for x in sample_counts]\n",
    "\n",
    "topk = 5\n",
    "new_idxes = []\n",
    "new_dists = []\n",
    "new_pos = []\n",
    "anomaly_idxes = [1379]\n",
    "for it, idx in enumerate(anomaly_idxes):\n",
    "    nearest = all_dist[idx, :].argsort()[:topk]\n",
    "    dists = all_dist[idx, nearest]\n",
    "    new_idxes += nearest.tolist()\n",
    "    new_dists += dists.tolist()\n",
    "    new_pos += [it] * topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpret_path(path, features):\n",
    "    conds = []\n",
    "    for key in path['range']:\n",
    "        feature = features[key]\n",
    "        values = path['range'][key]\n",
    "        name = feature['name']\n",
    "        op = 'is'\n",
    "        value = ''\n",
    "        if feature['dtype'] == 'category':\n",
    "            if len(values) < len(feature['values']) or key == 3:\n",
    "                t_values = [1 if (i >= values[0] and i <= values[1]) else 0 for i in range(1, len(feature['values']) + 1)]\n",
    "                values = t_values\n",
    "            is_negation = np.sum(values) + 1 == len(values)\n",
    "            if is_negation:\n",
    "                op = 'is not'\n",
    "                for i, d in enumerate(values):\n",
    "                    if d == 0:\n",
    "                        value = feature['values'][i]\n",
    "                        break\n",
    "            else:\n",
    "                for i, d in enumerate(values):\n",
    "                    if d == 1:\n",
    "                        value = value + ' or ' + feature['values'][i]\n",
    "                value = value[4:]\n",
    "        else:\n",
    "            op = 'in'\n",
    "            value = '%d ~ %d' % (values[0], values[1])\n",
    "        conds.append((name, op, value))\n",
    "    output_label = output_labels[path['output']]\n",
    "    # print(output_labels, path['output'])\n",
    "    return conds, output_label\n",
    "\n",
    "for index, feature in enumerate(features):\n",
    "    if feature['name'] in current_encoding:\n",
    "        feature['values'] = current_encoding[feature['name']]\n",
    "    else:\n",
    "        feature['values'] = feature['range']\n",
    "\n",
    "rules = []\n",
    "class_count = {}\n",
    "max_n_conds = 0\n",
    "for it, i in enumerate(new_idxes):\n",
    "    conds, output = interpret_path(paths[i], features)\n",
    "    #if class_count.get(output, 0) >= expected_one_class_count:\n",
    "    #    continue\n",
    "    class_count[output] = class_count.get(output, 0) + 1\n",
    "    rules.append({'cond': conds, 'predict': output, 'index': i, 'dist': new_dists[it] })\n",
    "    max_n_conds = max(len(conds), max_n_conds)\n",
    "    #if len(rules) >= expected_count:\n",
    "    #    break\n",
    "conds_per_line = 4\n",
    "max_n_conds = math.ceil(max_n_conds / conds_per_line) * conds_per_line\n",
    "\n",
    "\n",
    "rule_idxes = [rule['index'] for rule in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3719\n",
      "3718\n",
      "3720\n",
      "3721\n",
      "3717\n",
      "1572\n",
      "1571\n",
      "5122\n",
      "5123\n",
      "526\n",
      "1224\n",
      "3331\n",
      "3039\n",
      "463\n",
      "462\n",
      "4632\n",
      "4631\n",
      "7241\n",
      "4630\n",
      "448\n",
      "7869\n",
      "8420\n",
      "7868\n",
      "4380\n",
      "354\n",
      "1032\n",
      "1029\n",
      "1033\n",
      "4293\n",
      "3021\n",
      "10175\n",
      "10174\n",
      "10176\n",
      "10179\n",
      "10178\n",
      "5548\n",
      "5549\n",
      "6710\n",
      "6709\n",
      "8741\n",
      "7510\n",
      "7509\n",
      "7508\n",
      "7507\n",
      "7504\n",
      "71\n",
      "70\n",
      "69\n",
      "64\n",
      "4321\n",
      "10180\n",
      "10181\n",
      "6859\n",
      "7338\n",
      "3709\n",
      "1862\n",
      "1861\n",
      "1860\n",
      "1865\n",
      "1867\n",
      "2000\n",
      "1997\n",
      "1999\n",
      "1998\n",
      "2001\n",
      "4290\n",
      "4289\n",
      "4291\n",
      "3126\n",
      "4288\n",
      "185\n",
      "186\n",
      "184\n",
      "1175\n",
      "1178\n",
      "4821\n",
      "4822\n",
      "4820\n",
      "5836\n",
      "4375\n"
     ]
    }
   ],
   "source": [
    "f = open('3.csv', 'w')\n",
    "\n",
    "for it, rule in enumerate(rules):\n",
    "    print(new_idxes[it])\n",
    "    if it % topk == 0:\n",
    "        s = '' + str(new_pos[it])\n",
    "    else:\n",
    "        s = 'dist: %.4f' % (new_dists[it])\n",
    "    line = 0\n",
    "    n_conds = len(rule['cond'])\n",
    "    n_lines = math.ceil(n_conds / conds_per_line)\n",
    "    base = it - it % 5\n",
    "    overlap = np.sum(np.array(paths[rule['index']]['sample']) * np.array(paths[rules[base]['index']]['sample']))\n",
    "\n",
    "    for line in range(n_lines):\n",
    "        if line == 0:\n",
    "            s += ',%d,%d,%d,IF,' % (rule['index'], np.sum(paths[rule['index']]['sample']), overlap)\n",
    "        else:\n",
    "            s += ',,,,,'\n",
    "        for pos in range(conds_per_line):\n",
    "            i = pos + line * conds_per_line\n",
    "            if i < n_conds:\n",
    "                item = rule['cond'][i]\n",
    "                s += item[0] + ',' + item[1] + ',' + item[2] + ','\n",
    "                s += 'AND,' if i < n_conds - 1 else ','\n",
    "            else:\n",
    "                s += '...,...,...,...,'\n",
    "        if line == n_lines - 1:\n",
    "            s += 'THEN,' + rule['predict']\n",
    "        s += '\\n'\n",
    "    f.write(s + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 62, 33, 50, 28, 28, 14, 30, 14, 65, 44, 30]\n"
     ]
    }
   ],
   "source": [
    "anomaly_idxes = [x for i, x in enumerate(selected_path_idxes) if rule_type[i] > 0]\n",
    "print([np.sum(paths[i]['sample']) for i in anomaly_idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3719, 372, 1378, 5010, 2324]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_idxes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "1 1\n",
      "1 1\n",
      "6 2\n",
      "2 1\n",
      "2 2\n",
      "3 1\n",
      "13 2\n",
      "4 1\n",
      "17 2\n",
      "3 3\n",
      "2 1\n",
      "2 1\n",
      "9 2\n",
      "3 1\n",
      "2 2\n",
      "10 2\n",
      "14 2\n",
      "15 2\n",
      "16 2\n",
      "3 3\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "5 2\n",
      "3 3\n",
      "1 1\n",
      "2 1\n",
      "2 1\n",
      "9 2\n",
      "3 3\n",
      "14 3\n",
      "7 2\n",
      "7 2\n",
      "11 2\n"
     ]
    }
   ],
   "source": [
    "for it, i in enumerate(new_idxes):\n",
    "    base = new_idxes[it - it % 5]\n",
    "    print(np.sum(np.array(paths[i]['sample'])), np.sum(np.array(paths[i]['sample']) * np.array(paths[base]['sample'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nearest = all_dist[1379, :].argsort()[:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "print(np.max([np.sum(paths[i]['sample']) for i in selected_path_idxes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy Score is 0.828\n",
      "Precision Score is 0.8663101604278075\n",
      "F1 Score is 0.88283378746594\n",
      "Train\n",
      "Accuracy Score is 0.8932692307692308\n"
     ]
    }
   ],
   "source": [
    "from model.german_rf import get_model\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from lib.tree_extractor import path_extractor\n",
    "clf, (X_train, y_train, X_test, y_test, data_table), dataset, model, parameters = get_model()\n",
    "paths = path_extractor(clf, 'random forest', (X_train, y_train))\n",
    "\n",
    "target = 'credit_risk'\n",
    "X = data_table.drop(target, axis=1).values\n",
    "y = data_table[target].values\n",
    "from lib.tree_extractor import assign_samples\n",
    "assign_samples(paths, (X, y))\n",
    "\n",
    "features = data_table.columns[1:]\n",
    "new_feature = {}\n",
    "feature_pos = {}\n",
    "for index, feature in enumerate(features):\n",
    "    if ' - ' in feature:\n",
    "        name, p = feature.split(' - ')\n",
    "        p = int(p)\n",
    "        if name not in new_feature:\n",
    "            new_feature[name] = []\n",
    "        while p >= len(new_feature[name]):\n",
    "            new_feature[name].append(-1)\n",
    "        new_feature[name][p] = index\n",
    "    else:\n",
    "        new_feature[feature] = [index]\n",
    "\n",
    "feature_range = {}\n",
    "for key in new_feature:\n",
    "    if key in data_table.columns:\n",
    "        feature_range[key] = [data_table[key].min(), data_table[key].max() + 1]\n",
    "    else:\n",
    "        feature_range[key] = [0, len(new_feature[key])]\n",
    "    for i, j in enumerate(new_feature[key]):\n",
    "        feature_pos[j] = (key, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_labels = ['reject', 'accept']\n",
    "current_encoding = german_credit_encoding\n",
    "\n",
    "def interpret_path(path):\n",
    "    conds = {}\n",
    "    for k in path['range']:\n",
    "        name = feature_pos[k][0]\n",
    "        val = path['range'][k]\n",
    "        if name in current_encoding:\n",
    "            if name not in conds:\n",
    "                conds[name] = [1] * len(current_encoding[name])\n",
    "            if name in data_table.columns:\n",
    "                for i in range(feature_range[name][0], feature_range[name][1]):\n",
    "                    if i < val[0] or i > val[1]:\n",
    "                        conds[name][i - feature_range[name][0]] = 0\n",
    "            else:\n",
    "                if val[0] > 0:\n",
    "                    conds[name] = [0] * len(current_encoding[name])\n",
    "                    conds[name][feature_pos[k][1]] = 1\n",
    "                else:\n",
    "                    conds[name][feature_pos[k][1]] = 0\n",
    "        else:\n",
    "            cond = [max(feature_range[name][0], val[0]), min(feature_range[name][1], val[1])]\n",
    "            conds[name] = cond\n",
    "\n",
    "    output_conds = []\n",
    "    for name in conds:\n",
    "        val = conds[name]\n",
    "        op = 'is'\n",
    "        value = ''\n",
    "        if name in current_encoding:\n",
    "            is_negation = np.sum(val) + 1 == len(val) and len(val) > 2\n",
    "            if is_negation:\n",
    "                op = 'is not'\n",
    "                for i, d in enumerate(val):\n",
    "                    if d == 0:\n",
    "                        value = current_encoding[name][i]\n",
    "                        break\n",
    "            else:\n",
    "                for i, d in enumerate(val):\n",
    "                    if d == 1:\n",
    "                        value = value + ' or ' + current_encoding[name][i]\n",
    "                value = value[4:]\n",
    "        else:\n",
    "            if val[0] == feature_range[name][0]:\n",
    "                op = '<='\n",
    "                value = int(val[1])\n",
    "            elif val[1] == feature_range[name][1]:\n",
    "                op = '>='\n",
    "                value = int(val[0])\n",
    "            else:\n",
    "                op = 'in'\n",
    "                value = '%d to %d' % (int(val[0]), int(val[1]))\n",
    "        output_conds.append((name, op, value))\n",
    "    output_label = output_labels[path['output']]\n",
    "    # print(output_labels, path['output'])\n",
    "    return conds, output_conds, output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'savings': [1, 1, 0, 0, 0],\n",
       "  'property': [0, 1, 1, 1],\n",
       "  'purpose': [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'status': [1, 1, 0, 0],\n",
       "  'housing': [0, 1, 1],\n",
       "  'other_debtors': [1, 0, 0],\n",
       "  'number_credits': [0, 0, 1, 1],\n",
       "  'telephone': [1, 0]},\n",
       " [('savings', 'is', 'unknown/no savings account or ... <  100 DM'),\n",
       "  ('property', 'is not', 'real estate'),\n",
       "  ('purpose', 'is not', 'others'),\n",
       "  ('status', 'is', 'no checking account or ... < 0 DM'),\n",
       "  ('housing', 'is not', 'rent'),\n",
       "  ('other_debtors', 'is', 'none'),\n",
       "  ('number_credits', 'is', '4-5 or >= 6'),\n",
       "  ('telephone', 'is', 'No')],\n",
       " 'reject')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpret_path(paths[150])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e68ee7780e0be540c4e3141e92f7a462f6acd183a50724e7701ea314000c600"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e68ee7780e0be540c4e3141e92f7a462f6acd183a50724e7701ea314000c600"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
