{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sample import create_sampler\n",
    "from tree_extractor import path_extractor\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "random_state = 10\n",
    "\n",
    "class ExpModel:\n",
    "    def __init__(self, dataset, model):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.n_splits = 4\n",
    "        self._accuracy = []\n",
    "        self._precision = []\n",
    "        self._recall = []\n",
    "        self._f1_score = []\n",
    "\n",
    "    def init(self):\n",
    "        if self.model == 'lightgbm':\n",
    "            if self.dataset == 'bankruptcy':\n",
    "                self.target = 'Bankrupt?'\n",
    "                parameters = {\n",
    "                    'n_estimators': 400,\n",
    "                    'learning_rate': 0.25,\n",
    "                    'num_leaves': 250,\n",
    "                    'max_depth': 11,\n",
    "                    'min_data_in_leaf': 320,\n",
    "                    'lambda_l1': 0.65,\n",
    "                    'lambda_l2': 1.08,\n",
    "                    'bagging_fraction': 0.71,\n",
    "                    'bagging_freq': 8,\n",
    "                    'feature_fraction': 0.27,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/bank.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            self.data_table = data_table\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.parameters = parameters\n",
    "            \n",
    "            kf = KFold(n_splits = self.n_splits, random_state=random_state, shuffle=True)\n",
    "            self.splits = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                self.splits.append((train_index, test_index))\n",
    "            self.fold = 0\n",
    "\n",
    "    def has_next_fold(self):\n",
    "        return self.fold < len(self.splits)\n",
    "    \n",
    "    def next_fold(self):\n",
    "        self.fold += 1\n",
    "\n",
    "    def train(self):\n",
    "        sm = SMOTE(random_state=random_state)\n",
    "        data_table = self.data_table\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        parameters = self.parameters\n",
    "        train_index, test_index = self.splits[self.fold]\n",
    "        X_train = self.X[train_index]\n",
    "        y_train = self.y[train_index]\n",
    "        X_test = self.X[test_index]\n",
    "        y_test = self.y[test_index]\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.data_table = data_table\n",
    "        if self.model == 'RF':\n",
    "            clf = RandomForestClassifier(**parameters)\n",
    "        else:\n",
    "            clf = LGBMClassifier(**parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.clf = clf\n",
    "        self.y_pred = clf.predict(X_test)\n",
    "        self.features = data_table.drop(self.target, axis=1).columns.to_list()\n",
    "\n",
    "    def evaluate(self):\n",
    "        _accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        _precision = precision_score(self.y_test, self.y_pred)\n",
    "        _recall = recall_score(self.y_test, self.y_pred)\n",
    "        _f1_score = f1_score(self.y_test, self.y_pred)\n",
    "        print('Accuracy Score is', _accuracy)\n",
    "        print('Precision is', _precision)\n",
    "        print('Recall is', _recall)\n",
    "        print('F1 Score is', _f1_score)\n",
    "        self._accuracy.append(_accuracy)\n",
    "        self._precision.append(_precision)\n",
    "        self._recall.append(_recall)\n",
    "        self._f1_score.append(_f1_score)\n",
    "    \n",
    "    def summary(self):\n",
    "        return float(np.mean(self._accuracy)), float(np.mean(self._precision)), float(np.mean(self._recall)), float(np.mean(self._f1_score))\n",
    "\n",
    "    def oversampling(self, rate = 2):\n",
    "        is_continuous = []\n",
    "        is_categorical = []\n",
    "        is_integer = []\n",
    "\n",
    "        for feature in self.data_table.columns:\n",
    "            if feature == self.target:\n",
    "                continue\n",
    "            if self.data_table[feature].dtype == 'O':\n",
    "                is_continuous.append(False)\n",
    "                is_categorical.append(True)\n",
    "            else:\n",
    "                is_continuous.append(True)\n",
    "                is_categorical.append(False)\n",
    "            is_integer.append(False)\n",
    "        sampler = create_sampler(self.X_train, is_continuous, is_categorical, is_integer)\n",
    "        return sampler(len(self.X_train) * rate)\n",
    "\n",
    "    def generate_paths(self):\n",
    "        if self.model == 'RF':\n",
    "            paths = path_extractor(self.clf, 'random forest', (self.X_train, self.y_train))\n",
    "        else:\n",
    "            paths = path_extractor(self.clf, 'lightgbm')\n",
    "        print('num of paths', len(paths))\n",
    "        return paths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = 'bankruptcy'\n",
    "model = 'lightgbm'\n",
    "exp = ExpModel(dataset, model)\n",
    "exp.init()\n",
    "exp.train()\n",
    "paths = exp.generate_paths()\n",
    "exp.evaluate()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.65\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.71, subsample=1.0 will be ignored. Current value: bagging_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.27, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=320, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=320\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "num of paths 4111\n",
      "Accuracy Score is 0.9747800586510263\n",
      "Precision is 0.6440677966101694\n",
      "Recall is 0.6333333333333333\n",
      "F1 Score is 0.6386554621848739\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(len(paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3762\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tree_extractor import assign_samples_lgbm as assign_samples\n",
    "assign_samples(paths, (exp.X, exp.y))\n",
    "paths = [p for p in paths if p['coverage'] > 0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "last_paths = paths\n",
    "name2path = {}\n",
    "for index, path in enumerate(paths):\n",
    "    name2path[path['name']] = path\n",
    "    path['level'] = 0\n",
    "\n",
    "params = [600, 80]\n",
    "level_info = {}\n",
    "\n",
    "from model_extractor_maxnum import Extractor\n",
    "for level, n in enumerate(params):\n",
    "    tau = (n / 80) ** 0.5\n",
    "    ex = Extractor(last_paths, exp.X_train, exp.clf.predict(exp.X_train))\n",
    "    w, _, fidelity_train = ex.extract(n, tau)\n",
    "    [idx] = np.nonzero(w)\n",
    "\n",
    "    accuracy_train = ex.evaluate(w, exp.X_train, exp.y_train)\n",
    "    accuracy_test = ex.evaluate(w, exp.X_test, exp.y_test)\n",
    "    fidelity_test = ex.evaluate(w, exp.X_test, exp.clf.predict(exp.X_test))\n",
    "    print(level, n, 'accuracy_train', accuracy_train, 'accuracy_test', accuracy_test, 'fidelity_test', fidelity_test)\n",
    "    \n",
    "    level_info[level + 1] = {\n",
    "        'fidelity_test': fidelity_test,\n",
    "        'accuracy_test': accuracy_test,\n",
    "    }\n",
    "    for i in idx:\n",
    "        name2path[last_paths[i]['name']]['level'] = level + 1\n",
    "    curr_paths = [last_paths[i] for i in idx]\n",
    "    last_paths = curr_paths\n",
    "    print(len(last_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total path weight:  0.999999999999997\n",
      "0 600 accuracy_train 0.9995962858296327 accuracy_test 0.9695014662756598 fidelity_test 0.987683284457478\n",
      "600\n",
      "total path weight:  0.9999999999999992\n",
      "1 80 accuracy_train 0.9757771497779572 accuracy_test 0.9395894428152493 fidelity_test 0.950733137829912\n",
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(exp.clf)\n",
    "shap_values = explainer(exp.X)\n",
    "shap_values = shap_values[:,:,0]\n",
    "new_shaps = []\n",
    "\n",
    "new_feature = {}\n",
    "features = [feature for feature in exp.data_table.columns if feature != exp.target]\n",
    "for index, feature in enumerate(features):\n",
    "    if ' - ' in feature:\n",
    "        name, p = feature.split(' - ')\n",
    "        p = int(p)\n",
    "        if name not in new_feature:\n",
    "            new_feature[name] = []\n",
    "        while p >= len(new_feature[name]):\n",
    "            new_feature[name].append(-1)\n",
    "        new_feature[name][p] = index\n",
    "    else:\n",
    "        new_feature[feature] = [index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "features = []\n",
    "feature_index = {}\n",
    "feature_type = {}\n",
    "for key in new_feature:\n",
    "    if len(new_feature[key]) == 1:\n",
    "        i = new_feature[key][0]\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [min(exp.data_table[key].values), max(exp.data_table[key].values)],\n",
    "            \"importance\": exp.clf.feature_importances_[i],\n",
    "            \"dtype\": \"numeric\",\n",
    "        })\n",
    "        shaps = shap_values[:, i]\n",
    "        feature_index[i] = len(features) - 1\n",
    "        feature_type[i] = \"numeric\"\n",
    "    else:\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [0, len(new_feature[key])],\n",
    "            \"importance\": sum([exp.clf.feature_importances_[i] for i in new_feature[key] if i != -1]),\n",
    "            \"dtype\": \"categoric\",\n",
    "        })\n",
    "        feature_idxs = [i for i in  new_feature[key] if i != -1]\n",
    "        shaps = shap_values[:, feature_idxs[0]]\n",
    "        for i in feature_idxs[1:]:\n",
    "            shaps = shaps + shap_values[:, i]\n",
    "\n",
    "        for index, i in enumerate(new_feature[key]):\n",
    "            if i != -1:\n",
    "                feature_index[i] = [len(features) - 1, index]\n",
    "                feature_type[i] = \"categoric\"\n",
    "    new_shaps.append(shaps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for path in paths:\n",
    "    new_range = {}\n",
    "    for index in path['range']:\n",
    "        if feature_type[int(index)] == 'numeric':\n",
    "            i = feature_index[int(index)]\n",
    "            new_range[i] = path['range'][index]\n",
    "        else:\n",
    "            i, j = feature_index[int(index)]\n",
    "            if i not in new_range:\n",
    "                new_range[i] = [0] * features[i]['range'][1]\n",
    "                if path['range'][index][0] <= 1 and 1 <= path['range'][index][1]:\n",
    "                    new_range[i][j] = 1\n",
    "                else:\n",
    "                    for k in range(len(new_range[i])):\n",
    "                        if k != j:\n",
    "                            new_range[i][k] = 1\n",
    "                        new_range[i][j] = 0\n",
    "    path['range'] = new_range\n",
    "    path['represent'] = False\n",
    "\n",
    "for i in idx:\n",
    "    paths[i]['represent'] = True\n",
    "\n",
    "output_data = {\n",
    "    'paths': paths,\n",
    "    'features': features,\n",
    "    'selected': [paths[i]['name'] for i in idx],\n",
    "    'shap_values': new_shaps,\n",
    "    'model_info': {\n",
    "        'accuracy': exp._accuracy[-1],\n",
    "        'info': level_info,\n",
    "        'num_of_rules': len(paths),\n",
    "        'dataset': 'Taiwan Company Bankruptcy',\n",
    "        'model': 'LightGBM',\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pickle\n",
    "pickle.dump(output_data, open('output/bankruptcy0117.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "e4ca62cc624854f73843cd7b3352ae633eb01f3e4f77eee16509c1692ddd1ed1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}