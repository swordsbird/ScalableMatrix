{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sample import create_sampler\n",
    "from tree_extractor import path_extractor\n",
    "from model_extractor_maxnum import Extractor\n",
    "import pickle\n",
    "\n",
    "random_state = 126\n",
    "\n",
    "class ExpModel:\n",
    "    def __init__(self, dataset, model):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.n_splits = 4\n",
    "        self._accuracy = []\n",
    "        self._precision = []\n",
    "        self._recall = []\n",
    "        self._f1_score = []\n",
    "\n",
    "    def init(self):\n",
    "        if self.model == 'RF':\n",
    "            if self.dataset == 'breast_cancer':\n",
    "                self.target = 'diagnosis'\n",
    "                parameters = {\n",
    "                        'n_estimators': 200,\n",
    "                        'max_depth': 10,\n",
    "                        'random_state': random_state,\n",
    "                        'max_features': None,\n",
    "                }\n",
    "                data_table = pd.read_csv('data/cancer.csv')\n",
    "                data_table = data_table.drop(['id'], axis=1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'abalone':\n",
    "                self.target = 'Rings'\n",
    "                parameters = {\n",
    "                    'n_estimators': 80,\n",
    "                    # 'max_depth': 30,\n",
    "                    'random_state': 10,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                    'min_samples_split': 9,\n",
    "                    'min_samples_leaf': 5,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/abalone.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v <= 7 else 1 for v in y])\n",
    "            elif self.dataset == 'bankruptcy':\n",
    "                self.target = 'Bankrupt?'\n",
    "                parameters = {\n",
    "                        'n_estimators': 150,\n",
    "                        'max_depth': 15,\n",
    "                        'random_state': random_state,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/bank.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'diabetes':\n",
    "                self.target = 'class'\n",
    "                parameters = {\n",
    "                    'n_estimators': 100,\n",
    "                    'max_depth': 10,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': None,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/diabetes.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'german_credit':\n",
    "                self.target = 'Creditability'\n",
    "                parameters = {\n",
    "                    'random_state': random_state,\n",
    "                    'max_depth': 12,\n",
    "                    'n_estimators': 150,\n",
    "                    'max_leaf_nodes': 100,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'bootstrap': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/german.csv')          \n",
    "                purposes = [\n",
    "                    \"car (new)\",\n",
    "                    \"car (used)\",\n",
    "                    \"furniture/equipment\",\n",
    "                    \"radio/television\",\n",
    "                    \"domestic appliances\",\n",
    "                    \"repairs\",\n",
    "                    \"education\",\n",
    "                    \"vacation\",\n",
    "                    \"retraining\",\n",
    "                    \"business\",\n",
    "                    \"others\"\n",
    "                ]\n",
    "                qualitative_features = ['Account Balance' , 'Payment Status of Previous Credit' , 'Purpose' , 'Value Savings/Stocks' , 'Length of current employment' , 'Sex & Marital Status' , 'Guarantors' , 'Most valuable available asset' , 'Other installment plans' , 'Type of apartment' ,  'Occupation' , 'Telephone' , 'Foreign Worker']\n",
    "                for feature in qualitative_features:\n",
    "                    unique_values = np.unique(data_table[feature].values)\n",
    "                    sorted(unique_values)\n",
    "                    if int(unique_values[0]) == 0:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(i)] = data_table[feature].values == i\n",
    "                    else:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(int(i) - 1)] = data_table[feature].values == i\n",
    "\n",
    "                #    data_table['installment - '+ concurrent_credits[i]] = data_table['Other installment plans'].values == ix\n",
    "                #data_table['Account Balance'] = np.array([v if v < 4 else 0 for v in data_table['Account Balance'].values])\n",
    "                for feature in qualitative_features:\n",
    "                    data_table = data_table.drop(feature, axis = 1)\n",
    "                #data_table = data_table.drop('Other installment plans', axis = 1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'wine':\n",
    "                self.target = 'quality'\n",
    "                parameters = {\n",
    "                    'n_estimators': 150,\n",
    "                    'max_depth': 13,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/wine.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v < 6 else 1 for v in y])\n",
    "            self.data_table = data_table\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.parameters = parameters\n",
    "            \n",
    "            kf = KFold(n_splits = self.n_splits, random_state=random_state, shuffle=True)\n",
    "            self.splits = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                self.splits.append((train_index, test_index))\n",
    "            self.fold = 0\n",
    "\n",
    "    def has_next_fold(self):\n",
    "        return self.fold < len(self.splits)\n",
    "    \n",
    "    def next_fold(self):\n",
    "        self.fold += 1\n",
    "\n",
    "    def train(self):\n",
    "        sm = SMOTE(random_state=random_state)\n",
    "        data_table = self.data_table\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        parameters = self.parameters\n",
    "        train_index, test_index = self.splits[self.fold]\n",
    "        X_train = self.X[train_index]\n",
    "        y_train = self.y[train_index]\n",
    "        X_test = self.X[test_index]\n",
    "        y_test = self.y[test_index]\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.data_table = data_table\n",
    "        clf = RandomForestClassifier(**parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.clf = clf\n",
    "        self.y_pred = clf.predict(X_test)\n",
    "        self.features = data_table.drop(self.target, axis=1).columns.to_list()\n",
    "\n",
    "    def evaluate(self):\n",
    "        _accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        _precision = precision_score(self.y_test, self.y_pred)\n",
    "        _recall = recall_score(self.y_test, self.y_pred)\n",
    "        _f1_score = f1_score(self.y_test, self.y_pred)\n",
    "        print('Accuracy Score is', _accuracy)\n",
    "        print('Precision is', _precision)\n",
    "        print('Recall is', _recall)\n",
    "        print('F1 Score is', _f1_score)\n",
    "        self._accuracy.append(_accuracy)\n",
    "        self._precision.append(_precision)\n",
    "        self._recall.append(_recall)\n",
    "        self._f1_score.append(_f1_score)\n",
    "    \n",
    "    def summary(self):\n",
    "        return float(np.mean(self._accuracy)), float(np.mean(self._precision)), float(np.mean(self._recall)), float(np.mean(self._f1_score))\n",
    "\n",
    "    def oversampling(self, rate = 2):\n",
    "        is_continuous = []\n",
    "        is_categorical = []\n",
    "        is_integer = []\n",
    "\n",
    "        for feature in self.data_table.columns:\n",
    "            if feature == self.target:\n",
    "                continue\n",
    "            if self.data_table[feature].dtype == 'O':\n",
    "                is_continuous.append(False)\n",
    "                is_categorical.append(True)\n",
    "            else:\n",
    "                is_continuous.append(True)\n",
    "                is_categorical.append(False)\n",
    "            is_integer.append(False)\n",
    "        sampler = create_sampler(self.X_train, is_continuous, is_categorical, is_integer)\n",
    "        return sampler(len(self.X_train) * rate)\n",
    "\n",
    "    def generate_paths(self):\n",
    "        if self.model == 'RF':\n",
    "            paths = path_extractor(self.clf, 'random forest', (self.X_train, self.y_train))\n",
    "        else:\n",
    "            paths = path_extractor(self.clf, 'lightgbm')\n",
    "        print('num of paths', len(paths))\n",
    "        return paths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "dataset = 'german_credit'\n",
    "model = 'RF'\n",
    "exp = ExpModel(dataset, model)\n",
    "exp.init()\n",
    "exp.train()\n",
    "paths = exp.generate_paths()\n",
    "exp.evaluate()\n",
    "\n",
    "from tree_extractor import assign_samples\n",
    "assign_samples(paths, (exp.X, exp.y))\n",
    "paths = [p for p in paths if p['coverage'] > 0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num of paths 14554\n",
      "Accuracy Score is 0.828\n",
      "Precision is 0.8578680203045685\n",
      "Recall is 0.9184782608695652\n",
      "F1 Score is 0.8871391076115485\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "last_paths = paths\n",
    "name2path = {}\n",
    "for index, path in enumerate(paths):\n",
    "    name2path[path['name']] = path\n",
    "    path['level'] = 0\n",
    "\n",
    "params = [1000, 80]\n",
    "level_info = {}\n",
    "\n",
    "for level, n in enumerate(params):\n",
    "    tau = (n / 80) ** 0.5\n",
    "    ex = Extractor(last_paths, exp.X_train, exp.clf.predict(exp.X_train))\n",
    "    w, _, fidelity_train = ex.extract(n, tau)\n",
    "    [idx] = np.nonzero(w)\n",
    "\n",
    "    accuracy_train = ex.evaluate(w, exp.X_train, exp.y_train)\n",
    "    accuracy_test = ex.evaluate(w, exp.X_test, exp.y_test)\n",
    "    fidelity_test = ex.evaluate(w, exp.X_test, exp.clf.predict(exp.X_test))\n",
    "    print(level, n, 'accuracy_train', accuracy_train, 'accuracy_test', accuracy_test, 'fidelity_test', fidelity_test)\n",
    "    \n",
    "    level_info[level + 1] = {\n",
    "        'fidelity_test': fidelity_test,\n",
    "        'accuracy_test': accuracy_test,\n",
    "    }\n",
    "    for i in idx:\n",
    "        name2path[last_paths[i]['name']]['level'] = level + 1\n",
    "    curr_paths = [last_paths[i] for i in idx]\n",
    "    last_paths = curr_paths\n",
    "    print(len(last_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total path weight:  0.9999999999999902\n",
      "0 1000 accuracy_train 0.9467054263565892 accuracy_test 0.804 fidelity_test 0.96\n",
      "1000\n",
      "total path weight:  0.9999999999999996\n",
      "1 80 accuracy_train 0.8982558139534884 accuracy_test 0.76 fidelity_test 0.9\n",
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(exp.clf)\n",
    "shap_values = explainer(exp.X)\n",
    "shap_values = shap_values[:,:,0]\n",
    "new_shaps = []\n",
    "\n",
    "new_feature = {}\n",
    "features = [feature for feature in exp.data_table.columns if feature != exp.target]\n",
    "for index, feature in enumerate(features):\n",
    "    if ' - ' in feature:\n",
    "        name, p = feature.split(' - ')\n",
    "        p = int(p)\n",
    "        if name not in new_feature:\n",
    "            new_feature[name] = []\n",
    "        while p >= len(new_feature[name]):\n",
    "            new_feature[name].append(-1)\n",
    "        new_feature[name][p] = index\n",
    "    else:\n",
    "        new_feature[feature] = [index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "features = []\n",
    "feature_index = {}\n",
    "feature_type = {}\n",
    "for key in new_feature:\n",
    "    if len(new_feature[key]) == 1:\n",
    "        i = new_feature[key][0]\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [min(exp.data_table[key].values), max(exp.data_table[key].values)],\n",
    "            \"importance\": exp.clf.feature_importances_[i],\n",
    "            \"dtype\": \"numeric\",\n",
    "        })\n",
    "        shaps = shap_values[:, i]\n",
    "        feature_index[i] = len(features) - 1\n",
    "        feature_type[i] = \"numeric\"\n",
    "    else:\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [0, len(new_feature[key])],\n",
    "            \"importance\": sum([exp.clf.feature_importances_[i] for i in new_feature[key] if i != -1]),\n",
    "            \"dtype\": \"categoric\",\n",
    "        })\n",
    "        feature_idxs = [i for i in  new_feature[key] if i != -1]\n",
    "        shaps = shap_values[:, feature_idxs[0]]\n",
    "        for i in feature_idxs[1:]:\n",
    "            shaps = shaps + shap_values[:, i]\n",
    "\n",
    "        for index, i in enumerate(new_feature[key]):\n",
    "            if i != -1:\n",
    "                feature_index[i] = [len(features) - 1, index]\n",
    "                feature_type[i] = \"categoric\"\n",
    "    new_shaps.append(shaps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for path in paths:\n",
    "    new_range = {}\n",
    "    for index in path['range']:\n",
    "        if feature_type[index] == 'numeric':\n",
    "            i = feature_index[index]\n",
    "            new_range[i] = path['range'][index]\n",
    "        else:\n",
    "            i, j = feature_index[index]\n",
    "            if i not in new_range:\n",
    "                new_range[i] = [0] * features[i]['range'][1]\n",
    "                if path['range'][index][0] <= 1 and 1 <= path['range'][index][1]:\n",
    "                    new_range[i][j] = 1\n",
    "                else:\n",
    "                    for k in range(len(new_range[i])):\n",
    "                        if k != j:\n",
    "                            new_range[i][k] = 1\n",
    "                        new_range[i][j] = 0\n",
    "    path['range'] = new_range\n",
    "    path['represent'] = False\n",
    "\n",
    "for i in idx:\n",
    "    paths[i]['represent'] = True\n",
    "\n",
    "output_data = {\n",
    "    'paths': paths,\n",
    "    'features': features,\n",
    "    'selected': [paths[i]['name'] for i in idx],\n",
    "    'shap_values': new_shaps,\n",
    "    'model_info': {\n",
    "        'accuracy': exp._accuracy[-1],\n",
    "        'info': level_info,\n",
    "        'num_of_rules': len(paths),\n",
    "        'dataset': 'German Credit',\n",
    "        'model': 'Random Forest',\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pickle\n",
    "pickle.dump(output_data, open('output/german1211.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "features[17]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'Occupation',\n",
       " 'range': [0, 4],\n",
       " 'importance': 0.03760634137209534,\n",
       " 'dtype': 'categoric'}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sum(ex.Mat[10] == 1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(shap_values[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".values =\n",
      "array([[ 1.09110125e-01, -1.09110125e-01],\n",
      "       [ 3.01264698e-03, -3.01264698e-03],\n",
      "       [-1.24874332e-01,  1.24874332e-01],\n",
      "       [ 2.10891519e-03, -2.10891519e-03],\n",
      "       [-1.99799022e-02,  1.99799022e-02],\n",
      "       [ 3.40283799e-02, -3.40283799e-02],\n",
      "       [ 3.85628726e-02, -3.85628726e-02],\n",
      "       [ 5.60976830e-03, -5.60976830e-03],\n",
      "       [ 3.36153339e-02, -3.36153339e-02],\n",
      "       [ 3.85308858e-03, -3.85308858e-03],\n",
      "       [-2.39386825e-02,  2.39386825e-02],\n",
      "       [ 7.02421386e-03, -7.02421386e-03],\n",
      "       [ 1.96232689e-02, -1.96232689e-02],\n",
      "       [-1.74483971e-02,  1.74483971e-02],\n",
      "       [ 6.65478065e-02, -6.65478065e-02],\n",
      "       [ 6.73321595e-03, -6.73321595e-03],\n",
      "       [ 1.58162875e-03, -1.58162875e-03],\n",
      "       [-6.93273863e-05,  6.93273863e-05],\n",
      "       [ 5.12965848e-03, -5.12965848e-03],\n",
      "       [ 2.51444887e-03, -2.51444887e-03]])\n",
      "\n",
      ".base_values =\n",
      "array([0.50028956, 0.49971044])\n",
      "\n",
      ".data =\n",
      "array([   1,   18,    4,    2, 1049,    1,    2,    4,    2,    1,    4,\n",
      "          2,   21,    3,    1,    1,    3,    1,    1,    1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left_paths = [path for path in all_paths if path['fidelity'] > 0.75]\n",
    "left_paths.sort(key=lambda x: -x['coverage'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sample import create_sampler\n",
    "\n",
    "is_continuous = []\n",
    "is_categorical = []\n",
    "is_integer = []\n",
    "\n",
    "for feature in data_table.columns:\n",
    "    values = data_table[feature].values\n",
    "    if feature == 'Creditability':\n",
    "        continue\n",
    "    if data_table[feature].dtype == 'O':\n",
    "        is_continuous.append(False)\n",
    "        is_categorical.append(True)\n",
    "    else:\n",
    "        is_continuous.append(True)\n",
    "        is_categorical.append(False)\n",
    "    is_integer.append(False)\n",
    "sampler = create_sampler(X_train, is_continuous, is_categorical, is_integer)\n",
    "#X2 = sampler(len(X) * 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "e4ca62cc624854f73843cd7b3352ae633eb01f3e4f77eee16509c1692ddd1ed1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}