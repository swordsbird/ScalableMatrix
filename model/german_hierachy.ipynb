{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sample import create_sampler\n",
    "from tree_extractor import path_extractor\n",
    "from model_extractor_maxnum import Extractor\n",
    "import pickle\n",
    "\n",
    "random_state = 126\n",
    "\n",
    "class ExpModel:\n",
    "    def __init__(self, dataset, model):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.n_splits = 4\n",
    "        self._accuracy = []\n",
    "        self._precision = []\n",
    "        self._recall = []\n",
    "        self._f1_score = []\n",
    "\n",
    "    def init(self):\n",
    "        if self.model == 'RF':\n",
    "            if self.dataset == 'breast_cancer':\n",
    "                self.target = 'diagnosis'\n",
    "                parameters = {\n",
    "                        'n_estimators': 200,\n",
    "                        'max_depth': 10,\n",
    "                        'random_state': random_state,\n",
    "                        'max_features': None,\n",
    "                }\n",
    "                data_table = pd.read_csv('data/cancer.csv')\n",
    "                data_table = data_table.drop(['id'], axis=1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'abalone':\n",
    "                self.target = 'Rings'\n",
    "                parameters = {\n",
    "                    'n_estimators': 80,\n",
    "                    # 'max_depth': 30,\n",
    "                    'random_state': 10,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                    'min_samples_split': 9,\n",
    "                    'min_samples_leaf': 5,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/abalone.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v <= 7 else 1 for v in y])\n",
    "            elif self.dataset == 'bankruptcy':\n",
    "                self.target = 'Bankrupt?'\n",
    "                parameters = {\n",
    "                        'n_estimators': 150,\n",
    "                        'max_depth': 15,\n",
    "                        'random_state': random_state,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/bank.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'diabetes':\n",
    "                self.target = 'class'\n",
    "                parameters = {\n",
    "                    'n_estimators': 100,\n",
    "                    'max_depth': 10,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': None,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/diabetes.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'german_credit':\n",
    "                self.target = 'Creditability'\n",
    "                parameters = {\n",
    "                    'random_state': random_state,\n",
    "                    'max_depth': 12,\n",
    "                    'n_estimators': 150,\n",
    "                    'max_leaf_nodes': 100,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'bootstrap': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/german.csv')          \n",
    "                purposes = [\n",
    "                    \"car (new)\",\n",
    "                    \"car (used)\",\n",
    "                    \"furniture/equipment\",\n",
    "                    \"radio/television\",\n",
    "                    \"domestic appliances\",\n",
    "                    \"repairs\",\n",
    "                    \"education\",\n",
    "                    \"vacation\",\n",
    "                    \"retraining\",\n",
    "                    \"business\",\n",
    "                    \"others\"\n",
    "                ]\n",
    "                qualitative_features = ['Account Balance' , 'Payment Status of Previous Credit' , 'Purpose' , 'Value Savings/Stocks' , 'Length of current employment' , 'Sex & Marital Status' , 'Guarantors' , 'Most valuable available asset' , 'Other installment plans' , 'Type of apartment' ,  'Occupation' , 'Telephone' , 'Foreign Worker']\n",
    "                for feature in qualitative_features:\n",
    "                    unique_values = np.unique(data_table[feature].values)\n",
    "                    sorted(unique_values)\n",
    "                    if int(unique_values[0]) == 0:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(i)] = data_table[feature].values == i\n",
    "                    else:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(int(i) - 1)] = data_table[feature].values == i\n",
    "\n",
    "                #    data_table['installment - '+ concurrent_credits[i]] = data_table['Other installment plans'].values == ix\n",
    "                #data_table['Account Balance'] = np.array([v if v < 4 else 0 for v in data_table['Account Balance'].values])\n",
    "                for feature in qualitative_features:\n",
    "                    data_table = data_table.drop(feature, axis = 1)\n",
    "                #data_table = data_table.drop('Other installment plans', axis = 1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'wine':\n",
    "                self.target = 'quality'\n",
    "                parameters = {\n",
    "                    'n_estimators': 150,\n",
    "                    'max_depth': 13,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/wine.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v < 6 else 1 for v in y])\n",
    "            self.data_table = data_table\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.parameters = parameters\n",
    "            \n",
    "            kf = KFold(n_splits = self.n_splits, random_state=random_state, shuffle=True)\n",
    "            self.splits = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                self.splits.append((train_index, test_index))\n",
    "            self.fold = 0\n",
    "\n",
    "    def has_next_fold(self):\n",
    "        return self.fold < len(self.splits)\n",
    "    \n",
    "    def next_fold(self):\n",
    "        self.fold += 1\n",
    "\n",
    "    def train(self):\n",
    "        sm = SMOTE(random_state=random_state)\n",
    "        data_table = self.data_table\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        parameters = self.parameters\n",
    "        train_index, test_index = self.splits[self.fold]\n",
    "        X_train = self.X[train_index]\n",
    "        y_train = self.y[train_index]\n",
    "        X_test = self.X[test_index]\n",
    "        y_test = self.y[test_index]\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.data_table = data_table\n",
    "        clf = RandomForestClassifier(**parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.clf = clf\n",
    "        self.y_pred = clf.predict(X_test)\n",
    "        self.features = data_table.drop(self.target, axis=1).columns.to_list()\n",
    "\n",
    "    def evaluate(self):\n",
    "        _accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        _precision = precision_score(self.y_test, self.y_pred)\n",
    "        _recall = recall_score(self.y_test, self.y_pred)\n",
    "        _f1_score = f1_score(self.y_test, self.y_pred)\n",
    "        print('Accuracy Score is', _accuracy)\n",
    "        print('Precision is', _precision)\n",
    "        print('Recall is', _recall)\n",
    "        print('F1 Score is', _f1_score)\n",
    "        self._accuracy.append(_accuracy)\n",
    "        self._precision.append(_precision)\n",
    "        self._recall.append(_recall)\n",
    "        self._f1_score.append(_f1_score)\n",
    "    \n",
    "    def summary(self):\n",
    "        return float(np.mean(self._accuracy)), float(np.mean(self._precision)), float(np.mean(self._recall)), float(np.mean(self._f1_score))\n",
    "\n",
    "    def oversampling(self, rate = 2):\n",
    "        is_continuous = []\n",
    "        is_categorical = []\n",
    "        is_integer = []\n",
    "\n",
    "        for feature in self.data_table.columns:\n",
    "            if feature == self.target:\n",
    "                continue\n",
    "            if self.data_table[feature].dtype == 'O':\n",
    "                is_continuous.append(False)\n",
    "                is_categorical.append(True)\n",
    "            else:\n",
    "                is_continuous.append(True)\n",
    "                is_categorical.append(False)\n",
    "            is_integer.append(False)\n",
    "        sampler = create_sampler(self.X_train, is_continuous, is_categorical, is_integer)\n",
    "        return sampler(len(self.X_train) * rate)\n",
    "\n",
    "    def generate_paths(self):\n",
    "        if self.model == 'RF':\n",
    "            paths = path_extractor(self.clf, 'random forest', (self.X_train, self.y_train))\n",
    "        else:\n",
    "            paths = path_extractor(self.clf, 'lightgbm')\n",
    "        print('num of paths', len(paths))\n",
    "        return paths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "dataset = 'german_credit'\n",
    "model = 'RF'\n",
    "exp = ExpModel(dataset, model)\n",
    "exp.init()\n",
    "exp.train()\n",
    "paths = exp.generate_paths()\n",
    "exp.evaluate()\n",
    "\n",
    "from tree_extractor import assign_samples\n",
    "assign_samples(paths, (exp.X, exp.y))\n",
    "paths = [p for p in paths if p['coverage'] > 0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num of paths 14554\n",
      "Accuracy Score is 0.828\n",
      "Precision is 0.8578680203045685\n",
      "Recall is 0.9184782608695652\n",
      "F1 Score is 0.8871391076115485\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "last_paths = paths\n",
    "name2path = {}\n",
    "for index, path in enumerate(paths):\n",
    "    name2path[path['name']] = path\n",
    "    path['level'] = 0\n",
    "\n",
    "params = [2000, 400, 80]\n",
    "level_info = {}\n",
    "\n",
    "for level, n in enumerate(params):\n",
    "    tau = (n / 80) ** 0.5\n",
    "    ex = Extractor(last_paths, exp.X_train, exp.clf.predict(exp.X_train))\n",
    "    w, _, fidelity_train = ex.extract(n, tau)\n",
    "    [idx] = np.nonzero(w)\n",
    "\n",
    "    accuracy_train = ex.evaluate(w, exp.X_train, exp.y_train)\n",
    "    accuracy_test = ex.evaluate(w, exp.X_test, exp.y_test)\n",
    "    fidelity_test = ex.evaluate(w, exp.X_test, exp.clf.predict(exp.X_test))\n",
    "    print(level, n, 'accuracy_train', accuracy_train, 'accuracy_test', accuracy_test, 'fidelity_test', fidelity_test)\n",
    "    \n",
    "    level_info[level + 1] = {\n",
    "        'fidelity_test': fidelity_test,\n",
    "        'accuracy_test': accuracy_test,\n",
    "    }\n",
    "    for i in idx:\n",
    "        name2path[last_paths[i]['name']]['level'] = level + 1\n",
    "    curr_paths = [last_paths[i] for i in idx]\n",
    "    last_paths = curr_paths\n",
    "    print(len(last_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total path weight:  0.9999999999999969\n",
      "0 2000 accuracy_train 0.9486434108527132 accuracy_test 0.804 fidelity_test 0.952\n",
      "2000\n",
      "total path weight:  1.0000000000000062\n",
      "1 400 accuracy_train 0.939922480620155 accuracy_test 0.804 fidelity_test 0.936\n",
      "400\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/lizhen/projects/extree/model/model_extractor_maxnum.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  XXDis = 1 - XXAnd / XXOr\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-402e51e64685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/extree/model/model_extractor_maxnum.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, lamb, tau)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mpaths_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLP_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0maccuracy_origin1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_accuracy_on_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/extree/model/model_extractor_maxnum.py\u001b[0m in \u001b[0;36mgetWeight\u001b[0;34m(self, Mat)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXXDis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mXW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_outlier_factor_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mMXW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmXW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/neighbors/_lof.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0moutlier\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontamination\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_algorithm_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(exp.clf)\n",
    "shap_values = explainer(exp.X_train)\n",
    "\n",
    "new_feature = {}\n",
    "features = [feature for feature in exp.data_table.columns if feature != exp.target]\n",
    "for index, feature in enumerate(features):\n",
    "    if ' - ' in feature:\n",
    "        name, p = feature.split(' - ')\n",
    "        p = int(p)\n",
    "        if name not in new_feature:\n",
    "            new_feature[name] = []\n",
    "        while p >= len(new_feature[name]):\n",
    "            new_feature[name].append(-1)\n",
    "        new_feature[name][p] = index\n",
    "    else:\n",
    "        new_feature[feature] = [index]\n",
    "\n",
    "features = []\n",
    "feature_index = {}\n",
    "feature_type = {}\n",
    "for key in new_feature:\n",
    "    if len(new_feature[key]) == 1:\n",
    "        i = new_feature[key][0]\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [min(exp.data_table[key].values), max(exp.data_table[key].values)],\n",
    "            \"importance\": exp.clf.feature_importances_[i],\n",
    "            \"dtype\": \"numeric\",\n",
    "        })\n",
    "        feature_index[i] = len(features) - 1\n",
    "        feature_type[i] = \"numeric\"\n",
    "    else:\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [0, len(new_feature[key])],\n",
    "            \"importance\": sum([exp.clf.feature_importances_[i] for i in new_feature[key] if i != -1]),\n",
    "            \"dtype\": \"categoric\",\n",
    "        })\n",
    "        for index, i in enumerate(new_feature[key]):\n",
    "            if i != -1:\n",
    "                feature_index[i] = [len(features) - 1, index]\n",
    "                feature_type[i] = \"categoric\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'name': 'Duration of Credit (month)', 'range': [4, 72], 'importance': 0.05633576975957183, 'dtype': 'numeric'}\n",
      "{'name': 'Credit Amount', 'range': [250, 18424], 'importance': 0.056286726533428595, 'dtype': 'numeric'}\n",
      "{'name': 'Instalment per cent', 'range': [1, 4], 'importance': 0.023734298699895035, 'dtype': 'numeric'}\n",
      "{'name': 'Duration in Current address', 'range': [1, 4], 'importance': 0.031969786276545294, 'dtype': 'numeric'}\n",
      "{'name': 'Age (years)', 'range': [19, 75], 'importance': 0.03890911106561411, 'dtype': 'numeric'}\n",
      "{'name': 'No of Credits at this Bank', 'range': [1, 4], 'importance': 0.012889319099541809, 'dtype': 'numeric'}\n",
      "{'name': 'No of dependents', 'range': [1, 2], 'importance': 0.005498524800822959, 'dtype': 'numeric'}\n",
      "{'name': 'Account Balance', 'range': [0, 4], 'importance': 0.23189206974256948, 'dtype': 'categoric'}\n",
      "{'name': 'Payment Status of Previous Credit', 'range': [0, 5], 'importance': 0.0812119819629154, 'dtype': 'categoric'}\n",
      "{'name': 'Purpose', 'range': [0, 11], 'importance': 0.06025851112231475, 'dtype': 'categoric'}\n",
      "{'name': 'Value Savings/Stocks', 'range': [0, 5], 'importance': 0.07609398497353008, 'dtype': 'categoric'}\n",
      "{'name': 'Length of current employment', 'range': [0, 5], 'importance': 0.05574073339923258, 'dtype': 'categoric'}\n",
      "{'name': 'Sex & Marital Status', 'range': [0, 4], 'importance': 0.05549651707106262, 'dtype': 'categoric'}\n",
      "{'name': 'Guarantors', 'range': [0, 3], 'importance': 0.012733887928409984, 'dtype': 'categoric'}\n",
      "{'name': 'Most valuable available asset', 'range': [0, 4], 'importance': 0.06679681239100255, 'dtype': 'categoric'}\n",
      "{'name': 'Other installment plans', 'range': [0, 3], 'importance': 0.026565887660121145, 'dtype': 'categoric'}\n",
      "{'name': 'Type of apartment', 'range': [0, 3], 'importance': 0.04600475133627977, 'dtype': 'categoric'}\n",
      "{'name': 'Occupation', 'range': [0, 4], 'importance': 0.03760634137209534, 'dtype': 'categoric'}\n",
      "{'name': 'Telephone', 'range': [0, 2], 'importance': 0.020955307130983016, 'dtype': 'categoric'}\n",
      "{'name': 'Foreign Worker', 'range': [0, 2], 'importance': 0.0030196776740634285, 'dtype': 'categoric'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for path in paths:\n",
    "    new_range = {}\n",
    "    for index in path['range']:\n",
    "        if feature_type[index] == 'numeric':\n",
    "            i = feature_index[index]\n",
    "            new_range[i] = path['range'][index]\n",
    "        else:\n",
    "            i, j = feature_index[index]\n",
    "            if i not in new_range:\n",
    "                new_range[i] = [0] * features[i]['range'][1]\n",
    "                if path['range'][index][0] <= 1 and 1 <= path['range'][index][1]:\n",
    "                    new_range[i][j] = 1\n",
    "                else:\n",
    "                    for k in range(len(new_range[i])):\n",
    "                        if k != j:\n",
    "                            new_range[i][k] = 1\n",
    "                        new_range[i][j] = 0\n",
    "    path['range'] = new_range\n",
    "    path['represent'] = False\n",
    "\n",
    "for i in idx:\n",
    "    paths[i]['represent'] = True\n",
    "\n",
    "output_data = {\n",
    "    'paths': paths,\n",
    "    'features': features,\n",
    "    'selected': [paths[i]['name'] for i in idx],\n",
    "    'shap_values': shap_values,\n",
    "    'model_info': {\n",
    "        'accuracy': exp._accuracy[-1],\n",
    "        'info': level_info,\n",
    "        'num_of_rules': len(paths),\n",
    "        'dataset': 'German Credit',\n",
    "        'model': 'Random Forest',\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pickle\n",
    "pickle.dump(output_data, open('output/german1210.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "features[17]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'Occupation',\n",
       " 'range': [0, 4],\n",
       " 'importance': 0.03760634137209534,\n",
       " 'dtype': 'categoric'}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sum(ex.Mat[10] == 1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(shap_values[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".values =\n",
      "array([[ 1.09110125e-01, -1.09110125e-01],\n",
      "       [ 3.01264698e-03, -3.01264698e-03],\n",
      "       [-1.24874332e-01,  1.24874332e-01],\n",
      "       [ 2.10891519e-03, -2.10891519e-03],\n",
      "       [-1.99799022e-02,  1.99799022e-02],\n",
      "       [ 3.40283799e-02, -3.40283799e-02],\n",
      "       [ 3.85628726e-02, -3.85628726e-02],\n",
      "       [ 5.60976830e-03, -5.60976830e-03],\n",
      "       [ 3.36153339e-02, -3.36153339e-02],\n",
      "       [ 3.85308858e-03, -3.85308858e-03],\n",
      "       [-2.39386825e-02,  2.39386825e-02],\n",
      "       [ 7.02421386e-03, -7.02421386e-03],\n",
      "       [ 1.96232689e-02, -1.96232689e-02],\n",
      "       [-1.74483971e-02,  1.74483971e-02],\n",
      "       [ 6.65478065e-02, -6.65478065e-02],\n",
      "       [ 6.73321595e-03, -6.73321595e-03],\n",
      "       [ 1.58162875e-03, -1.58162875e-03],\n",
      "       [-6.93273863e-05,  6.93273863e-05],\n",
      "       [ 5.12965848e-03, -5.12965848e-03],\n",
      "       [ 2.51444887e-03, -2.51444887e-03]])\n",
      "\n",
      ".base_values =\n",
      "array([0.50028956, 0.49971044])\n",
      "\n",
      ".data =\n",
      "array([   1,   18,    4,    2, 1049,    1,    2,    4,    2,    1,    4,\n",
      "          2,   21,    3,    1,    1,    3,    1,    1,    1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left_paths = [path for path in all_paths if path['fidelity'] > 0.75]\n",
    "left_paths.sort(key=lambda x: -x['coverage'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sample import create_sampler\n",
    "\n",
    "is_continuous = []\n",
    "is_categorical = []\n",
    "is_integer = []\n",
    "\n",
    "for feature in data_table.columns:\n",
    "    values = data_table[feature].values\n",
    "    if feature == 'Creditability':\n",
    "        continue\n",
    "    if data_table[feature].dtype == 'O':\n",
    "        is_continuous.append(False)\n",
    "        is_categorical.append(True)\n",
    "    else:\n",
    "        is_continuous.append(True)\n",
    "        is_categorical.append(False)\n",
    "    is_integer.append(False)\n",
    "sampler = create_sampler(X_train, is_continuous, is_categorical, is_integer)\n",
    "#X2 = sampler(len(X) * 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "e4ca62cc624854f73843cd7b3352ae633eb01f3e4f77eee16509c1692ddd1ed1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}