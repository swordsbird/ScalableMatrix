{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sample import create_sampler\n",
    "from tree_extractor import path_extractor\n",
    "from model_extractor_maxnum import Extractor\n",
    "import pickle\n",
    "\n",
    "random_state = 24\n",
    "\n",
    "class ExpModel:\n",
    "    def __init__(self, dataset, model):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.n_splits = 4\n",
    "        self._accuracy = []\n",
    "        self._precision = []\n",
    "        self._recall = []\n",
    "        self._f1_score = []\n",
    "\n",
    "    def init(self):\n",
    "        if self.model == 'RF':\n",
    "            if self.dataset == 'breast_cancer':\n",
    "                self.target = 'diagnosis'\n",
    "                parameters = {\n",
    "                        'n_estimators': 200,\n",
    "                        'max_depth': 10,\n",
    "                        'random_state': random_state,\n",
    "                        'max_features': None,\n",
    "                }\n",
    "                data_table = pd.read_csv('data/cancer.csv')\n",
    "                data_table = data_table.drop(['id'], axis=1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'abalone':\n",
    "                self.target = 'Rings'\n",
    "                parameters = {\n",
    "                    'n_estimators': 80,\n",
    "                    # 'max_depth': 30,\n",
    "                    'random_state': 10,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                    'min_samples_split': 9,\n",
    "                    'min_samples_leaf': 5,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/abalone.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v <= 7 else 1 for v in y])\n",
    "            elif self.dataset == 'bankruptcy':\n",
    "                self.target = 'Bankrupt?'\n",
    "                parameters = {\n",
    "                        'n_estimators': 150,\n",
    "                        'max_depth': 15,\n",
    "                        'random_state': random_state,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/bank.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'diabetes':\n",
    "                self.target = 'class'\n",
    "                parameters = {\n",
    "                    'n_estimators': 100,\n",
    "                    'max_depth': 10,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': None,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/diabetes.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'german_credit':\n",
    "                self.target = 'credit_risk'\n",
    "                #random_state = 24\n",
    "                parameters = {\n",
    "                    'random_state': random_state,\n",
    "                    'max_depth': 12,\n",
    "                    'n_estimators': 150,\n",
    "                    'max_leaf_nodes': 100,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'bootstrap': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/german.csv')\n",
    "                qualitative_features = [\n",
    "                    'credit_history', 'purpose', 'other_debtors', \n",
    "                    'property', 'other_installment_plans', \n",
    "                    'housing', 'job', 'people_liable', 'telephone',\n",
    "                    'foreign_worker', 'number_credits',\n",
    "                ]\n",
    "                for feature in qualitative_features:\n",
    "                    unique_values = np.unique(data_table[feature].values)\n",
    "                    sorted(unique_values)\n",
    "                    if int(unique_values[0]) == 0:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(i)] = data_table[feature].values == i\n",
    "                    else:\n",
    "                        for i in unique_values:\n",
    "                            data_table[feature + ' - '+ str(int(i) - 1)] = data_table[feature].values == i\n",
    "                data_table['personal_status_sex'] = 1 * (data_table['personal_status_sex'].values == 3)\n",
    "                print(data_table['personal_status_sex'].values)\n",
    "                #data_table['personal_status_sex - 0'] = data_table[feature].values != 2\n",
    "                #data_table['personal_status_sex - 1'] = data_table[feature].values == 2\n",
    "                #data_table = data_table.drop('personal_status_sex', axis = 1)\n",
    "                #    data_table['installment - '+ concurrent_credits[i]] = data_table['Other installment plans'].values == ix\n",
    "                #data_table['Account Balance'] = np.array([v if v < 4 else 0 for v in data_table['Account Balance'].values])\n",
    "                for feature in qualitative_features:\n",
    "                    data_table = data_table.drop(feature, axis = 1)\n",
    "                #data_table = data_table.drop('Other installment plans', axis = 1)\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "            elif self.dataset == 'wine':\n",
    "                self.target = 'quality'\n",
    "                parameters = {\n",
    "                    'n_estimators': 150,\n",
    "                    'max_depth': 13,\n",
    "                    'random_state': random_state,\n",
    "                    'max_features': 'auto',\n",
    "                    'oob_score': True,\n",
    "                }\n",
    "\n",
    "                data_table = pd.read_csv('data/wine.csv')\n",
    "                X = data_table.drop(self.target, axis=1).values\n",
    "                y = data_table[self.target].values\n",
    "                y = np.array([0 if v < 6 else 1 for v in y])\n",
    "            self.data_table = data_table\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.parameters = parameters\n",
    "            \n",
    "            kf = KFold(n_splits = self.n_splits, random_state=random_state, shuffle=True)\n",
    "            self.splits = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                self.splits.append((train_index, test_index))\n",
    "            self.fold = 0\n",
    "\n",
    "    def has_next_fold(self):\n",
    "        return self.fold < len(self.splits)\n",
    "    \n",
    "    def next_fold(self):\n",
    "        self.fold += 1\n",
    "\n",
    "    def train(self):\n",
    "        sm = SMOTE(random_state=random_state)\n",
    "        data_table = self.data_table\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        parameters = self.parameters\n",
    "        train_index, test_index = self.splits[self.fold]\n",
    "        X_train = self.X[train_index]\n",
    "        y_train = self.y[train_index]\n",
    "        X_test = self.X[test_index]\n",
    "        y_test = self.y[test_index]\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.data_table = data_table\n",
    "        clf = RandomForestClassifier(**parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        self.clf = clf\n",
    "        self.y_pred = clf.predict(X_test)\n",
    "        self.features = data_table.drop(self.target, axis=1).columns.to_list()\n",
    "\n",
    "    def evaluate(self):\n",
    "        _accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        _precision = precision_score(self.y_test, self.y_pred)\n",
    "        _recall = recall_score(self.y_test, self.y_pred)\n",
    "        _f1_score = f1_score(self.y_test, self.y_pred)\n",
    "        print('Accuracy Score is', _accuracy)\n",
    "        print('Precision is', _precision)\n",
    "        print('Recall is', _recall)\n",
    "        print('F1 Score is', _f1_score)\n",
    "        self._accuracy.append(_accuracy)\n",
    "        self._precision.append(_precision)\n",
    "        self._recall.append(_recall)\n",
    "        self._f1_score.append(_f1_score)\n",
    "    \n",
    "    def summary(self):\n",
    "        return float(np.mean(self._accuracy)), float(np.mean(self._precision)), float(np.mean(self._recall)), float(np.mean(self._f1_score))\n",
    "\n",
    "    def oversampling(self, rate = 2):\n",
    "        is_continuous = []\n",
    "        is_categorical = []\n",
    "        is_integer = []\n",
    "\n",
    "        for feature in self.data_table.columns:\n",
    "            if feature == self.target:\n",
    "                continue\n",
    "            if self.data_table[feature].dtype == 'O':\n",
    "                is_continuous.append(False)\n",
    "                is_categorical.append(True)\n",
    "            else:\n",
    "                is_continuous.append(True)\n",
    "                is_categorical.append(False)\n",
    "            is_integer.append(False)\n",
    "        sampler = create_sampler(self.X_train, is_continuous, is_categorical, is_integer)\n",
    "        return sampler(len(self.X_train) * rate)\n",
    "\n",
    "    def generate_paths(self):\n",
    "        if self.model == 'RF':\n",
    "            paths = path_extractor(self.clf, 'random forest', (self.X_train, self.y_train))\n",
    "        else:\n",
    "            paths = path_extractor(self.clf, 'lightgbm')\n",
    "        print('num of paths', len(paths))\n",
    "        return paths\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset = 'german_credit'\n",
    "model = 'RF'\n",
    "\n",
    "exp = ExpModel(dataset, model)\n",
    "exp.init()\n",
    "exp.train()\n",
    "paths = exp.generate_paths()\n",
    "exp.evaluate()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1\n",
      " 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 1 0 0\n",
      " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 1\n",
      " 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0\n",
      " 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1\n",
      " 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1\n",
      " 1]\n",
      "num of paths 14644\n",
      "Accuracy Score is 0.804\n",
      "Precision is 0.8241206030150754\n",
      "Recall is 0.9213483146067416\n",
      "F1 Score is 0.870026525198939\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "from tree_extractor import assign_samples\n",
    "assign_samples(paths, (exp.X, exp.y))\n",
    "paths = [p for p in paths if p['coverage'] > 0]\n",
    "print(len(paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14174\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "last_paths = paths\n",
    "name2path = {}\n",
    "for index, path in enumerate(paths):\n",
    "    name2path[path['name']] = path\n",
    "    path['level'] = 0\n",
    "\n",
    "params = [1000, 80]\n",
    "level_info = {}\n",
    "\n",
    "for level, n in enumerate(params):\n",
    "    tau = (n / 80) ** 0.65\n",
    "    ex = Extractor(last_paths, exp.X_train, exp.clf.predict(exp.X_train))\n",
    "    w, _, fidelity_train = ex.extract(n, tau)\n",
    "    [idx] = np.nonzero(w)\n",
    "\n",
    "    accuracy_train = ex.evaluate(w, exp.X_train, exp.y_train)\n",
    "    accuracy_test = ex.evaluate(w, exp.X_test, exp.y_test)\n",
    "    fidelity_test = ex.evaluate(w, exp.X_test, exp.clf.predict(exp.X_test))\n",
    "    print(level, n, 'accuracy_train', accuracy_train, 'accuracy_test', accuracy_test, 'fidelity_test', fidelity_test)\n",
    "    \n",
    "    level_info[level + 1] = {\n",
    "        'fidelity_test': fidelity_test,\n",
    "        'accuracy_test': accuracy_test,\n",
    "    }\n",
    "    for i in idx:\n",
    "        name2path[last_paths[i]['name']]['level'] = level + 1\n",
    "    curr_paths = [last_paths[i] for i in idx]\n",
    "    last_paths = curr_paths\n",
    "    print(len(last_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total path weight:  0.9999999999999876\n",
      "0 1000 accuracy_train 0.9521072796934866 accuracy_test 0.816 fidelity_test 0.96\n",
      "1000\n",
      "total path weight:  0.9999999999999996\n",
      "1 80 accuracy_train 0.9032567049808429 accuracy_test 0.756 fidelity_test 0.844\n",
      "80\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(exp.clf)\n",
    "shap_values = explainer(exp.X)\n",
    "shap_values = shap_values[:,:,0]\n",
    "new_shaps = []\n",
    "\n",
    "new_feature = {}\n",
    "features = [feature for feature in exp.data_table.columns if feature != exp.target]\n",
    "for index, feature in enumerate(features):\n",
    "    if ' - ' in feature:\n",
    "        name, p = feature.split(' - ')\n",
    "        p = int(p)\n",
    "        if name not in new_feature:\n",
    "            new_feature[name] = []\n",
    "        while p >= len(new_feature[name]):\n",
    "            new_feature[name].append(-1)\n",
    "        new_feature[name][p] = index\n",
    "    else:\n",
    "        new_feature[feature] = [index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "features = []\n",
    "feature_index = {}\n",
    "feature_type = {}\n",
    "for key in new_feature:\n",
    "    if len(new_feature[key]) == 1:\n",
    "        i = new_feature[key][0]\n",
    "        if key in ['status', 'savings', 'employment_duration', 'installment_rate', 'present_residence', 'personal_status_sex']:\n",
    "            min_value = min(exp.data_table[key].values)\n",
    "            max_value = max(exp.data_table[key].values)\n",
    "            unique_values = np.unique(exp.data_table[key].values)\n",
    "            sorted(unique_values)\n",
    "            features.append({\n",
    "                \"name\": key,\n",
    "                \"range\": [0, max_value - min_value + 1],\n",
    "                \"values\": unique_values.tolist(),\n",
    "                \"min\": min_value,\n",
    "                \"importance\": exp.clf.feature_importances_[i],\n",
    "                \"dtype\": \"categoric\",\n",
    "            })\n",
    "            feature_type[i] = \"categoric\"\n",
    "        else:\n",
    "            features.append({\n",
    "                \"name\": key,\n",
    "                \"range\": [min(exp.data_table[key].values), max(exp.data_table[key].values)],\n",
    "                \"importance\": exp.clf.feature_importances_[i],\n",
    "                \"dtype\": \"numeric\",\n",
    "            })\n",
    "            feature_type[i] = \"numeric\"\n",
    "        shaps = shap_values[:, i]\n",
    "        feature_index[i] = [len(features) - 1, 0]\n",
    "    else:\n",
    "        features.append({\n",
    "            \"name\": key,\n",
    "            \"range\": [0, len(new_feature[key])],\n",
    "            \"values\": new_feature[key],\n",
    "            \"min\": 0,\n",
    "            \"importance\": sum([exp.clf.feature_importances_[i] for i in new_feature[key] if i != -1]),\n",
    "            \"dtype\": \"categoric\",\n",
    "        })\n",
    "        feature_idxs = [i for i in  new_feature[key] if i != -1]\n",
    "        shaps = shap_values[:, feature_idxs[0]]\n",
    "        for i in feature_idxs[1:]:\n",
    "            shaps = shaps + shap_values[:, i]\n",
    "\n",
    "        for index, i in enumerate(new_feature[key]):\n",
    "            if i != -1:\n",
    "                feature_index[i] = [len(features) - 1, index]\n",
    "                feature_type[i] = \"categoric\"\n",
    "    new_shaps.append(shaps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for path in paths:\n",
    "    if not path.get('represent', True):\n",
    "        continue\n",
    "    new_range = {}\n",
    "    for index in path['range']:\n",
    "        i, j = feature_index[index]\n",
    "        if feature_type[index] == 'numeric':\n",
    "            r = path['range'][index]\n",
    "            key = features[i]['name']\n",
    "            if exp.data_table[key].dtype == np.int64:\n",
    "                if r[0] < 0:\n",
    "                    r[0] = 0\n",
    "                if r[1] > features[i]['range'][1]:\n",
    "                    r[1] = features[i]['range'][1]\n",
    "                if features[index]['range'][0] > 0:\n",
    "                    if r[0] < int(r[0]) + 1e-7:\n",
    "                        r[0] = int(r[0]) - 1\n",
    "                    else:\n",
    "                        r[0] = int(r[0])\n",
    "                    if r[1] > int(r[1]) + 1e-7:\n",
    "                        r[1] = int(r[1])\n",
    "                else:\n",
    "                    if r[0] > int(r[0]) + 1e-7:\n",
    "                        r[0] = int(r[0]) + 0.5\n",
    "                    if r[1] > int(r[1]) + 1e-7:\n",
    "                        r[1] = int(r[1]) + 0.5\n",
    "            new_range[i] = r\n",
    "        else:\n",
    "            key = features[i]['name']\n",
    "            if key in ['status', 'savings', 'employment_duration', 'installment_rate', 'present_residence', 'personal_status_sex']:\n",
    "                new_range[i] = [0] * features[i]['range'][1]\n",
    "                min_value = features[i]['min']\n",
    "                r = path['range'][index]\n",
    "                for j in range(features[i]['range'][1]):\n",
    "                    if j + min_value >= r[0] and j + min_value <= r[1]:\n",
    "                        new_range[i][j] = 1\n",
    "            else:\n",
    "                if i not in new_range:\n",
    "                    new_range[i] = [0] * features[i]['range'][1]\n",
    "                    if path['range'][index][0] <= 1 and 1 <= path['range'][index][1]:\n",
    "                        new_range[i][j] = 1\n",
    "                    else:\n",
    "                        for k in range(len(new_range[i])):\n",
    "                            if k != j:\n",
    "                                new_range[i][k] = 1\n",
    "                            new_range[i][j] = 0\n",
    "    path['new_range'] = new_range\n",
    "    path['represent'] = False\n",
    "\n",
    "for i in idx:\n",
    "    paths[i]['represent'] = True\n",
    "\n",
    "output_data = {\n",
    "    'paths': paths,\n",
    "    'features': features,\n",
    "    'selected': [paths[i]['name'] for i in idx],\n",
    "    'shap_values': new_shaps,\n",
    "    'model_info': {\n",
    "        'accuracy': exp._accuracy[-1],\n",
    "        'info': level_info,\n",
    "        'num_of_rules': len(paths),\n",
    "        'dataset': 'German Credit',\n",
    "        'model': 'Random Forest',\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "import pickle\n",
    "pickle.dump(output_data, open('output/german0117_2.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "for path in paths:\n",
    "    path['range'] = path['new_range']\n",
    "    del path['new_range']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'name': 'status', 'range': [0, 4], 'values': [1, 2, 3, 4], 'min': 1, 'importance': 0.15251070283754695, 'dtype': 'categoric'}, {'name': 'duration', 'range': [4, 72], 'importance': 0.05695306807074818, 'dtype': 'numeric'}, {'name': 'amount', 'range': [250, 18424], 'importance': 0.06248818859485609, 'dtype': 'numeric'}, {'name': 'savings', 'range': [0, 5], 'values': [1, 2, 3, 4, 5], 'min': 1, 'importance': 0.04699644446291882, 'dtype': 'categoric'}, {'name': 'employment_duration', 'range': [0, 5], 'values': [1, 2, 3, 4, 5], 'min': 1, 'importance': 0.04186566532332252, 'dtype': 'categoric'}, {'name': 'installment_rate', 'range': [0, 4], 'values': [1, 2, 3, 4], 'min': 1, 'importance': 0.03927210304662811, 'dtype': 'categoric'}, {'name': 'personal_status_sex', 'range': [0, 2], 'values': [0, 1], 'min': 0, 'importance': 0.028227516841829833, 'dtype': 'categoric'}, {'name': 'present_residence', 'range': [0, 4], 'values': [1, 2, 3, 4], 'min': 1, 'importance': 0.03166133959410306, 'dtype': 'categoric'}, {'name': 'age', 'range': [19, 75], 'importance': 0.04399282332159122, 'dtype': 'numeric'}, {'name': 'credit_history', 'range': [0, 5], 'values': [9, 10, 11, 12, 13], 'min': 0, 'importance': 0.0927286228953923, 'dtype': 'categoric'}, {'name': 'purpose', 'range': [0, 11], 'values': [14, 15, 16, 17, 18, 19, 20, -1, 21, 22, 23], 'min': 0, 'importance': 0.09422511801557495, 'dtype': 'categoric'}, {'name': 'other_debtors', 'range': [0, 3], 'values': [24, 25, 26], 'min': 0, 'importance': 0.012078034915546338, 'dtype': 'categoric'}, {'name': 'property', 'range': [0, 4], 'values': [27, 28, 29, 30], 'min': 0, 'importance': 0.08076711059155782, 'dtype': 'categoric'}, {'name': 'other_installment_plans', 'range': [0, 3], 'values': [31, 32, 33], 'min': 0, 'importance': 0.053018377805291575, 'dtype': 'categoric'}, {'name': 'housing', 'range': [0, 3], 'values': [34, 35, 36], 'min': 0, 'importance': 0.049444124712131964, 'dtype': 'categoric'}, {'name': 'job', 'range': [0, 4], 'values': [37, 38, 39, 40], 'min': 0, 'importance': 0.04150734943065712, 'dtype': 'categoric'}, {'name': 'people_liable', 'range': [0, 2], 'values': [41, 42], 'min': 0, 'importance': 0.016195620250494154, 'dtype': 'categoric'}, {'name': 'telephone', 'range': [0, 2], 'values': [43, 44], 'min': 0, 'importance': 0.026214038997592497, 'dtype': 'categoric'}, {'name': 'foreign_worker', 'range': [0, 2], 'values': [45, 46], 'min': 0, 'importance': 0.003033187671936436, 'dtype': 'categoric'}, {'name': 'number_credits', 'range': [0, 4], 'values': [47, 48, 49, 50], 'min': 0, 'importance': 0.026820562620280125, 'dtype': 'categoric'}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "lp = [p for p in paths if 19 in p['new_range']]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "lp[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'range': {3: [-100000000000000.0, 3.9953023195266724],\n",
       "  33: [0.9958832561969757, 100000000000000.0],\n",
       "  6: [-100000000000000.0, 0.034650105983018875],\n",
       "  30: [-100000000000000.0, 0.013599947094917297],\n",
       "  27: [0.965991199016571, 100000000000000.0],\n",
       "  16: [-100000000000000.0, 0.22568358480930328],\n",
       "  7: [1.5, 100000000000000.0],\n",
       "  46: [-100000000000000.0, 0.5],\n",
       "  5: [3.2413134574890137, 100000000000000.0],\n",
       "  26: [-100000000000000.0, 0.7586865127086639],\n",
       "  39: [0.5, 100000000000000.0],\n",
       "  48: [-100000000000000.0, 0.5]},\n",
       " 'value': 0.0625,\n",
       " 'weight': 1,\n",
       " 'tree_index': 0,\n",
       " 'rule_index': 45,\n",
       " 'name': 'r0_45',\n",
       " 'confidence': 0.75,\n",
       " 'sample': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'sample_id': [18,\n",
       "  48,\n",
       "  60,\n",
       "  385,\n",
       "  398,\n",
       "  420,\n",
       "  425,\n",
       "  444,\n",
       "  494,\n",
       "  500,\n",
       "  817,\n",
       "  951,\n",
       "  967,\n",
       "  972],\n",
       " 'distribution': [4, 10],\n",
       " 'output': 1,\n",
       " 'coverage': 0.014,\n",
       " 'level': 0,\n",
       " 'new_range': {3: [1, 1, 1, 0, 0],\n",
       "  13: [0, 0, 1],\n",
       "  6: [1, 0],\n",
       "  12: [1, 1, 1, 0],\n",
       "  10: [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  7: [0, 1, 1, 1],\n",
       "  18: [1, 0],\n",
       "  5: [0, 0, 0, 1],\n",
       "  11: [1, 1, 0],\n",
       "  15: [0, 0, 1, 0],\n",
       "  19: [1, 0, 1, 1]},\n",
       " 'represent': False}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(shap_values[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".values =\n",
      "array([[ 1.09110125e-01, -1.09110125e-01],\n",
      "       [ 3.01264698e-03, -3.01264698e-03],\n",
      "       [-1.24874332e-01,  1.24874332e-01],\n",
      "       [ 2.10891519e-03, -2.10891519e-03],\n",
      "       [-1.99799022e-02,  1.99799022e-02],\n",
      "       [ 3.40283799e-02, -3.40283799e-02],\n",
      "       [ 3.85628726e-02, -3.85628726e-02],\n",
      "       [ 5.60976830e-03, -5.60976830e-03],\n",
      "       [ 3.36153339e-02, -3.36153339e-02],\n",
      "       [ 3.85308858e-03, -3.85308858e-03],\n",
      "       [-2.39386825e-02,  2.39386825e-02],\n",
      "       [ 7.02421386e-03, -7.02421386e-03],\n",
      "       [ 1.96232689e-02, -1.96232689e-02],\n",
      "       [-1.74483971e-02,  1.74483971e-02],\n",
      "       [ 6.65478065e-02, -6.65478065e-02],\n",
      "       [ 6.73321595e-03, -6.73321595e-03],\n",
      "       [ 1.58162875e-03, -1.58162875e-03],\n",
      "       [-6.93273863e-05,  6.93273863e-05],\n",
      "       [ 5.12965848e-03, -5.12965848e-03],\n",
      "       [ 2.51444887e-03, -2.51444887e-03]])\n",
      "\n",
      ".base_values =\n",
      "array([0.50028956, 0.49971044])\n",
      "\n",
      ".data =\n",
      "array([   1,   18,    4,    2, 1049,    1,    2,    4,    2,    1,    4,\n",
      "          2,   21,    3,    1,    1,    3,    1,    1,    1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "left_paths = [path for path in all_paths if path['fidelity'] > 0.75]\n",
    "left_paths.sort(key=lambda x: -x['coverage'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sample import create_sampler\n",
    "\n",
    "is_continuous = []\n",
    "is_categorical = []\n",
    "is_integer = []\n",
    "\n",
    "for feature in data_table.columns:\n",
    "    values = data_table[feature].values\n",
    "    if feature == 'Creditability':\n",
    "        continue\n",
    "    if data_table[feature].dtype == 'O':\n",
    "        is_continuous.append(False)\n",
    "        is_categorical.append(True)\n",
    "    else:\n",
    "        is_continuous.append(True)\n",
    "        is_categorical.append(False)\n",
    "    is_integer.append(False)\n",
    "sampler = create_sampler(X_train, is_continuous, is_categorical, is_integer)\n",
    "#X2 = sampler(len(X) * 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for key in exp.data_table.columns:\n",
    "    print(key, exp.data_table[key].dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "credit_risk int64\n",
      "status int64\n",
      "duration int64\n",
      "amount int64\n",
      "savings int64\n",
      "employment_duration int64\n",
      "installment_rate int64\n",
      "personal_status_sex int64\n",
      "present_residence int64\n",
      "age int64\n",
      "credit_history - 0 bool\n",
      "credit_history - 1 bool\n",
      "credit_history - 2 bool\n",
      "credit_history - 3 bool\n",
      "credit_history - 4 bool\n",
      "purpose - 0 bool\n",
      "purpose - 1 bool\n",
      "purpose - 2 bool\n",
      "purpose - 3 bool\n",
      "purpose - 4 bool\n",
      "purpose - 5 bool\n",
      "purpose - 6 bool\n",
      "purpose - 8 bool\n",
      "purpose - 9 bool\n",
      "purpose - 10 bool\n",
      "other_debtors - 0 bool\n",
      "other_debtors - 1 bool\n",
      "other_debtors - 2 bool\n",
      "property - 0 bool\n",
      "property - 1 bool\n",
      "property - 2 bool\n",
      "property - 3 bool\n",
      "other_installment_plans - 0 bool\n",
      "other_installment_plans - 1 bool\n",
      "other_installment_plans - 2 bool\n",
      "housing - 0 bool\n",
      "housing - 1 bool\n",
      "housing - 2 bool\n",
      "job - 0 bool\n",
      "job - 1 bool\n",
      "job - 2 bool\n",
      "job - 3 bool\n",
      "people_liable - 0 bool\n",
      "people_liable - 1 bool\n",
      "telephone - 0 bool\n",
      "telephone - 1 bool\n",
      "foreign_worker - 0 bool\n",
      "foreign_worker - 1 bool\n",
      "number_credits - 0 bool\n",
      "number_credits - 1 bool\n",
      "number_credits - 2 bool\n",
      "number_credits - 3 bool\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(exp.data_table['personal_status_sex'].max())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "e4ca62cc624854f73843cd7b3352ae633eb01f3e4f77eee16509c1692ddd1ed1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}